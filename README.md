## MGM Evaluation

This repository contains various Python scripts to run MGM evaluattion tests, which typically take a set of MGM outputs assoicated with certain media files and compare them with the ground-truth assoicated with the same media. Various criteria specific to each category of MGMs are used to calculate the performance metrics. Test results can then be visualized in the forms of barcharts and tables etc to facilitate evaluation.

The MGM evaluation tests are run by AMP REST backend, upon requests from AMP UI, and the results are presented back to AMP UI via graphical visualization as well as json files.

Further information on how to install, config, run, as well as contribute to the AMP project can be found at [AMP Bootstrap](https://github.com/AudiovisualMetadataPlatform/amp_bootstrap)
